# Phase 3 â€” Structured NLP & Evaluation

## ðŸŽ¯ Goal

Phase 3 introduces structured NLP tasks and evaluation benchmarks, positioning the project as a regional reference for serious NLP and research.

This phase enables:
- ðŸ” Enterprise NLP applications (RAG, search)
- ðŸŒ Translation and multilingual models
- ðŸ“Š Standardized LLM evaluation
- ðŸŽ“ Academic research

---

## ðŸ“¦ Datasets in Phase 3

1. **Named Entity Recognition (NER)**
2. **Text Classification (Topics)**
3. **Translation** (srâ†”hrâ†”bs, â†”EN)
4. **LLM Evaluation / Benchmark Dataset**

---

## ðŸ·ï¸ Dataset 1: Named Entity Recognition (NER)

### Purpose

Support RAG systems, search applications, and enterprise NLP with locally-relevant named entities.

### Entities

- `PERSON` - people
- `LOCATION` - locations (cities, countries, regions)
- `ORGANIZATION` - organizations, companies, institutions
- `DATE` - dates and temporal markers
- `EVENT` - events (optional)

### Format

```jsonl
{
  "text": "Predsjednik BiH Denis BeÄ‡iroviÄ‡ posjetio je Sarajevo.",
  "entities": [
    {"text": "Denis BeÄ‡iroviÄ‡", "label": "PERSON", "start": 17, "end": 32},
    {"text": "Sarajevo", "label": "LOCATION", "start": 47, "end": 55}
  ],
  "language": "bs"
}
```

### Construction

- **Automatic annotation** - using existing NER tools (spaCy, Stanza)
- **Human correction** - at least 20% of samples
- **Silver + Gold subsets** - clear quality marking

### Target Size

- **15,000 - 30,000** annotated sentences

---

## ðŸ“‚ Dataset 2: Text Classification (Topics)

### Purpose

Topic classification for news and web content, useful for filtering, routing, and recommendations.

### Categories

- Politics (Politika)
- Economy (Ekonomija)
- Sports (Sport)
- Technology (Tehnologija)
- Health (Zdravlje)
- Culture (Kultura)
- Crime (Kriminal)
- Lifestyle (Å½ivotni stil)

### Format

```jsonl
{
  "text": "Article text...",
  "category": "ekonomija",
  "language": "sr"
}
```

### Sources

- Already categorized news articles
- Automatic extraction + validation

### Target Size

- **20,000 - 50,000** classified documents

---

## ðŸŒ Dataset 3: Translation Datasets

### 3a) SR â†” HR â†” BOS Parallel Dataset

#### Purpose

Parallel sentences between South Slavic variants, which is a **rare and very valuable** resource.

#### Format

```jsonl
{
  "bs": "Odluka je donesena danas.",
  "hr": "Odluka je donesena danas.",
  "sr": "Odluka je doneta danas.",
  "source": "official_communication"
}
```

#### Sources

- Agency news in multiple languages
- Official documents (EU, laws)
- Institutional announcements

#### Target Size

- **10,000 - 25,000** parallel sentences

---

### 3b) SR/BOS/HR â†” EN Translation Dataset

#### Purpose

Enable fine-tuning of translation models between sr/bs/hr and English.

#### Format

```jsonl
{
  "sr": "Predsjednik je danas odrÅ¾ao govor.",
  "en": "The president delivered a speech today.",
  "direction": "sr-en"
}
```

#### Sources

- Parallel news articles
- EU and international documents
- Subtitles (optional, with license)

#### Target Size

- **15,000 - 40,000** parallel sentences

---

## ðŸ“Š Dataset 4: LLM Evaluation / Benchmark

### Purpose

Provide standardized evaluation benchmark for sr/bs/hr language models, including:

- â“ Question Answering
- ðŸ§  Reasoning
- ðŸ“š Reading comprehension
- ðŸŒ Local cultural knowledge
- ðŸ§® Math reasoning

### Format

```jsonl
{
  "question": "Ko je bio prvi predsjednik Bosne i Hercegovine?",
  "answer": "Alija IzetbegoviÄ‡",
  "category": "history",
  "difficulty": "easy",
  "language": "bs"
}
```

### Construction

- Mix of manual and adapted questions
- Focus on local context (geography, history, culture)
- Multiple-choice + open-ended questions

### Target Size

- **5,000 - 10,000** evaluation questions

---

## âœ… Success Criteria

Phase 3 is considered successful if:

1. âœ… Research-grade annotation quality
2. âœ… Clear evaluation splits (train/dev/test)
3. âœ… Citability in academic papers
4. âœ… Usage in industry and research projects
5. âœ… Reproducible evaluation protocols

---

## â±ï¸ Time Estimate

| Dataset | Duration |
|---------|----------|
| NER | 3-5 weeks |
| Text Classification | 1-2 weeks |
| Translation (srâ†”hrâ†”bs) | 4-6 weeks |
| Translation (â†”EN) | 2-3 weeks |
| LLM Benchmark | 2-3 weeks |
| **TOTAL** | **12-19 weeks** |

---

## ðŸ”— Related Documents

- [Phase 2 - LLM Enablement](PHASE_2.md)
- [Phase 4 - Domain Specific](PHASE_4.md)
- [Methodology](METHODOLOGY.md)

---

## ðŸ“Œ Notes

- **Annotation quality** is critical - better small but accurate dataset
- **Inter-annotator agreement** should be > 0.8
- **Test sets** must not be publicly available (leakage prevention)
- **Benchmark results** should be reproducible
